"""Evaluation Worker - Periodically fetches and processes evaluation tasks

Architecture Design:
    This worker directly accesses the database (shared with API) for simplicity
    and performance in single-machine or same-network deployments.
    
    Worker <---> Database <---> API
             (shared database/operations.py)

Design Trade-offs:
    âœ“ Simple: No HTTP overhead, straightforward code
    âœ“ Fast: Direct database access without extra API layer
    âœ“ Independent: Worker and API can run independently
    âœ— Coupled: Requires shared database access (not suitable for distributed deployment)

When to Refactor:
    If you need distributed deployment (e.g., multiple workers on different machines),
    consider migrating to a task queue system like Celery:
        - Use message broker (Redis/RabbitMQ) for task distribution
        - Workers consume tasks from queue instead of polling database
        - API publishes tasks to queue instead of writing to database directly

Worker Features:
- Fetches one task at a time (atomic operation to avoid conflicts)
- Updates status to 'running' immediately after claiming
- Supports multiple concurrent workers
- Single task failure does not affect other tasks
"""

import asyncio
import time
import logging
import signal
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

import schedule
from rich.console import Console

from models import TaskStatus
from database import (
    claim_next_pending_task,
    get_document_by_id,
    update_task_status,
    update_task_progress,
)
from evaluator import MortgageRAGEvaluator, EvaluatorConfig


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('.data/worker.log'),
        logging.StreamHandler()
    ]
)

# ç¦ç”¨ç¬¬ä¸‰æ–¹åº“çš„è¯¦ç»†æ—¥å¿—
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("anthropic").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

console = Console()


class EvaluationWorker:
    """è¯„ä¼° Worker
    
    å®šæ—¶æ£€æŸ¥å¾…å¤„ç†ä»»åŠ¡ï¼Œé€ä¸ªæ‰§è¡Œè¯„ä¼°æµç¨‹ã€‚
    """
    
    def __init__(self, config: EvaluatorConfig, check_interval: int = 60):
        """åˆå§‹åŒ– Worker
        
        Args:
            config: è¯„ä¼°å™¨é…ç½®
            check_interval: æ£€æŸ¥ä»»åŠ¡é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 60 ç§’
        """
        self.config = config
        self.check_interval = check_interval
        self.evaluator = MortgageRAGEvaluator(config)
        self.should_stop = False
        
        # æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """å¤„ç†åœæ­¢ä¿¡å·"""
        console.print("\n[yellow]æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ...[/yellow]")
        self.should_stop = True
    
    def start(self):
        """å¯åŠ¨ Worker"""
        console.print("[bold green]ğŸš€ Evaluation Worker å¯åŠ¨[/bold green]")
        console.print(f"æ£€æŸ¥é—´éš”: {self.check_interval} ç§’")
        console.print(f"LLM URI: {self.config.llm_uri}\n")
        
        # å®šæ—¶ä»»åŠ¡ï¼šæ¯ check_interval ç§’æ£€æŸ¥ä¸€æ¬¡
        schedule.every(self.check_interval).seconds.do(self._process_next_task)
        
        # å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡
        self._process_next_task()
        
        # ä¸»å¾ªç¯
        while not self.should_stop:
            schedule.run_pending()
            time.sleep(1)
        
        console.print("[bold yellow]Worker å·²åœæ­¢[/bold yellow]")
    
    def _process_next_task(self):
        """å¤„ç†ä¸‹ä¸€ä¸ªå¾…å¤„ç†ä»»åŠ¡"""
        try:
            # åŸå­æ€§è·å–ä¸€ä¸ªä»»åŠ¡
            task = claim_next_pending_task()
            
            if not task:
                logger.info("æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥...")
                return
            
            logger.info(f"è·å–åˆ°ä»»åŠ¡ {task.id}ï¼Œå¼€å§‹å¤„ç†...")
            console.print(f"\n[bold cyan]ğŸ“‹ ä»»åŠ¡ {task.id} - å¼€å§‹å¤„ç†[/bold cyan]")
            
            # è·å–æ–‡æ¡£ä¿¡æ¯
            document = get_document_by_id(task.document_id)
            if not document:
                error_msg = f"æ–‡æ¡£ {task.document_id} ä¸å­˜åœ¨"
                logger.error(error_msg)
                update_task_status(
                    task.id,
                    status=TaskStatus.FAILED,
                    completed_at=datetime.now(),
                    error=error_msg
                )
                return
            
            console.print(f"æ–‡æ¡£: {document.filename} ({document.total_pages} é¡µ)")
            console.print(f"é¡µç èŒƒå›´: {task.start_page or 1} - {task.end_page or document.total_pages}")
            console.print(f"æµ‹è¯•ç”¨ä¾‹æ•°: {task.num_test_cases}\n")
            
            # æ‰§è¡Œè¯„ä¼°
            self._execute_evaluation(task, document)
            
        except Exception as e:
            logger.exception(f"å¤„ç†ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            console.print(f"[bold red]âŒ é”™è¯¯: {e}[/bold red]")
    
    def _execute_evaluation(self, task, document):
        """æ‰§è¡Œè¯„ä¼°æµç¨‹"""
        try:
            # æ‰§è¡Œè¯„ä¼°
            result = asyncio.run(
                self.evaluator.eval(
                    document.file_path,
                    start_page=task.start_page,
                    end_page=task.end_page
                )
            )
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
            update_task_status(
                task.id,
                status=TaskStatus.COMPLETED,
                progress=100,
                completed_at=datetime.now(),
                result_path=str(result.report_excel_path),
                dataset_path=str(result.dataset_path),
                avg_score=result.avg_score,
                metrics_summary=result.metrics_summary
            )
            
            console.print(f"[bold green]âœ… ä»»åŠ¡ {task.id} å®Œæˆï¼å¹³å‡åˆ†: {result.avg_score:.2f}[/bold green]")
            logger.info(f"ä»»åŠ¡ {task.id} å®Œæˆï¼Œå¹³å‡åˆ†: {result.avg_score:.2f}")
            
        except Exception as e:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            error_msg = str(e)
            update_task_status(
                task.id,
                status=TaskStatus.FAILED,
                completed_at=datetime.now(),
                error=error_msg
            )
            
            console.print(f"[bold red]âŒ ä»»åŠ¡ {task.id} å¤±è´¥: {error_msg}[/bold red]")
            logger.exception(f"ä»»åŠ¡ {task.id} å¤±è´¥")


def main():
    """Worker å…¥å£"""
    try:
        # ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
        config = EvaluatorConfig.from_env()
        
        # å¯åŠ¨ Worker
        worker = EvaluationWorker(config, check_interval=10)
        worker.start()
        
    except KeyboardInterrupt:
        console.print("\n[yellow]Worker è¢«ç”¨æˆ·ä¸­æ–­[/yellow]")
    except Exception as e:
        console.print(f"[bold red]Worker å¯åŠ¨å¤±è´¥: {e}[/bold red]")
        logger.exception("Worker å¯åŠ¨å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()
