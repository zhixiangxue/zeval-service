"""Mortgage RAG è¯„ä¼°å™¨ - æ ¸å¿ƒè¯„ä¼°æµç¨‹"""

import time
import tempfile
from datetime import datetime
from pathlib import Path
from pydantic import BaseModel, Field
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn

# Fix torch.xpu compatibility issue for PyTorch < 2.5
import torch
if not hasattr(torch, 'xpu'):
    class MockXPU:
        @staticmethod
        def is_available():
            return False
    torch.xpu = MockXPU()

from zeval.synthetic_data.readers.docling import DoclingReader
from zeval.synthetic_data.splitters import MarkdownHeaderSplitter
from zeval.synthetic_data.transforms.extractors import (
    SummaryExtractor,
    KeyphrasesExtractor,
    EntitiesExtractor
)
from zeval.synthetic_data.generators.persona import generate_personas, Persona
from zeval.synthetic_data.generators.single_hop import generate_single_hop
from zeval.evaluation.metrics import (
    Faithfulness,
    ContextRelevance,
    ContextRecall,
    ContextPrecision,
    AnswerRelevancy,
    AnswerCorrectness,
)
from zeval.evaluation.runner import MetricRunner
from zeval.evaluation.reporter import EvaluationReporter
from zeval.schemas.eval import EvalDataset

from .config import EvaluatorConfig
from .result import EvalResult

console = Console()


# Mortgage é¢†åŸŸçš„ Persona æ¨¡å‹
class HomeBuyerPersona(Persona):
    """US Home Buyer persona with financial attributes"""
    credit_score: int = Field(
        description="Credit score (300-850), affects mortgage eligibility and interest rates"
    )
    dti_ratio: float = Field(
        description="Debt-to-Income ratio as percentage (typical max is 43%)"
    )
    down_payment_percent: float = Field(
        description="Down payment as percentage of home price (typically 3-20%)"
    )
    budget_range: str = Field(
        description="Home price budget range (e.g., '$300K-$500K')"
    )


class MortgageRAGEvaluator:
    """Mortgage RAG è¯„ä¼°å™¨
    
    ç«¯åˆ°ç«¯è¯„ä¼°æµç¨‹ï¼šPDF â†’ è¯»å– â†’ åˆ†å‰² â†’ å¯ŒåŒ– â†’ ç”Ÿæˆæµ‹è¯•é›† â†’ è°ƒç”¨RAG â†’ è¯„ä¼° â†’ æŠ¥å‘Š
    
    Example:
        config = EvaluatorConfig.from_env()
        evaluator = MortgageRAGEvaluator(config)
        result = await evaluator.eval("/path/to/doc.pdf")
        print(f"æŠ¥å‘Š: {result.report_excel_path}")
        print(f"å¹³å‡åˆ†: {result.avg_score:.2f}")
    """
    
    def __init__(self, config: EvaluatorConfig):
        self.config = config
        self.console = console
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.reader = self._init_reader()
        self.splitter = MarkdownHeaderSplitter()
        
        # Extractors
        self.extractor = (
            SummaryExtractor(config.llm_uri, config.api_key, max_sentences=2)
            | KeyphrasesExtractor(config.llm_uri, config.api_key, max_num=5)
            | EntitiesExtractor(config.llm_uri, config.api_key, max_num=5)
        )
        
        # Metrics
        self.metrics = [
            Faithfulness(config.llm_uri, config.api_key),
            ContextRelevance(config.llm_uri, config.api_key),
            ContextRecall(config.llm_uri, config.api_key),
            ContextPrecision(config.llm_uri, config.api_key),
            AnswerRelevancy(config.llm_uri, config.api_key),
            AnswerCorrectness(config.llm_uri, config.api_key),
        ]
        
        self.runner = MetricRunner(metrics=self.metrics)
        self.reporter = EvaluationReporter(config.llm_uri, config.api_key)
    
    def _init_reader(self) -> DoclingReader:
        """åˆå§‹åŒ– PDF Reader"""
        from docling.datamodel.pipeline_options import PdfPipelineOptions
        from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions
        
        pdf_options = PdfPipelineOptions()
        pdf_options.accelerator_options = AcceleratorOptions(
            num_threads=8,
            device=AcceleratorDevice.CPU
        )
        
        return DoclingReader(pdf_pipeline_options=pdf_options)
    
    async def eval(
        self, 
        file_path: str, 
        start_page: int | None = None,
        end_page: int | None = None
    ) -> EvalResult:
        """æ‰§è¡Œç«¯åˆ°ç«¯è¯„ä¼°
        
        Args:
            file_path: PDF æ–‡ä»¶è·¯å¾„
            start_page: èµ·å§‹é¡µç ï¼ˆä»1å¼€å§‹ï¼‰ï¼ŒNoneè¡¨ç¤ºä»ç¬¬ä¸€é¡µå¼€å§‹
            end_page: ç»“æŸé¡µç ï¼ˆåŒ…å«ï¼‰ï¼ŒNoneè¡¨ç¤ºåˆ°æœ€åä¸€é¡µ
            
        Returns:
            EvalResult: è¯„ä¼°ç»“æœï¼ŒåŒ…å«æ‰€æœ‰è¾“å‡ºè·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
            
        Example:
            # è¯„ä¼°æ•´ä¸ªæ–‡æ¡£
            result = await evaluator.eval("/path/to/doc.pdf")
            
            # åªè¯„ä¼°ç¬¬10-20é¡µ
            result = await evaluator.eval("/path/to/doc.pdf", start_page=10, end_page=20)
        """
        start_time = time.time()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ç”Ÿæˆå”¯ä¸€å·¥ä½œç›®å½• IDï¼ˆ6ä½éšæœºå­—ç¬¦ï¼‰
        import random
        import string
        work_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
        
        # åœ¨ç³»ç»Ÿä¸´æ—¶ç›®å½•ä¸‹åˆ›å»ºå·¥ä½œç›®å½•
        work_dir = Path(tempfile.gettempdir()) / f"zeval_{work_id}"
        work_dir.mkdir(parents=True, exist_ok=True)
        
        # å¦‚æœæŒ‡å®šäº†é¡µç èŒƒå›´ï¼Œå…ˆåˆ‡å‰² PDF
        actual_file_path = file_path
        if start_page is not None or end_page is not None:
            actual_file_path = self._extract_pages(file_path, start_page, end_page, work_dir)
        
        # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
        page_info = ""
        if start_page is not None or end_page is not None:
            page_info = f"\n[bold]é¡µç èŒƒå›´[/bold]: {start_page or 1} - {end_page or 'æœ€åä¸€é¡µ'}"
        
        self.console.print()
        self.console.print(Panel.fit(
            f"[bold]æ–‡ä»¶[/bold]: {Path(file_path).name}"
            f"{page_info}\n"
            f"[bold cyan]å·¥ä½œç›®å½•[/bold cyan]: {work_dir}\n"
            f"[bold]æ—¶é—´[/bold]: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            title="ğŸš€ å¼€å§‹è¯„ä¼°",
            border_style="cyan"
        ))
        self.console.print()
        
        # 1. è¯»å– PDF
        self.console.print("[cyan]â–¶[/cyan] [bold]Step 1/6:[/bold] è¯»å– PDF...")
        document = self.reader.read(str(actual_file_path))
        self.console.print(f"  [green]âœ“[/green] è¯»å–å®Œæˆ: {len(document.pages)} é¡µ")
        
        # ä¿å­˜ document content åˆ°å·¥ä½œç›®å½•
        doc_content_path = work_dir / "document_content.md"
        doc_content_path.write_text(document.content, encoding='utf-8')
        self.console.print(f"  [blue]â„¹[/blue] å†…å®¹å·²ä¿å­˜: {doc_content_path.name}\n")
        
        # 2. åˆ†å‰²æ–‡æ¡£
        self.console.print("[cyan]â–¶[/cyan] [bold]Step 2/6:[/bold] åˆ†å‰²æ–‡æ¡£...")
        units = document.split(self.splitter)
        self.console.print(f"  [green]âœ“[/green] åˆ†å‰²å®Œæˆ: {len(units)} ä¸ªå•å…ƒ\n")
        
        # 3. å¯ŒåŒ–å•å…ƒ
        self.console.print("[cyan]â–¶[/cyan] [bold]Step 3/6:[/bold] å¯ŒåŒ–å•å…ƒ...")
        enriched_units = await self.extractor.transform(
            units[:self.config.max_units],
            max_concurrency=self.config.max_concurrency
        )
        self.console.print(f"  [green]âœ“[/green] å¯ŒåŒ–å®Œæˆ: {len(enriched_units)} ä¸ªå•å…ƒ\n")
        
        # 4. ç”Ÿæˆæµ‹è¯•æ•°æ®é›†
        self.console.print("[cyan]â–¶[/cyan] [bold]Step 4/6:[/bold] ç”Ÿæˆæµ‹è¯•æ•°æ®é›†...")
        dataset = await self._generate_dataset(enriched_units)
        self.console.print(f"  [green]âœ“[/green] ç”Ÿæˆå®Œæˆ: {len(dataset.cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹\n")
        
        # ä¿å­˜æ•°æ®é›†
        dataset_path = work_dir / "dataset.json"
        dataset.to_json(str(dataset_path))
        
        # 5. è°ƒç”¨ RAG ç³»ç»Ÿï¼ˆMockï¼‰
        self.console.print("[cyan]â–¶[/cyan] [bold]Step 5/6:[/bold] è°ƒç”¨ RAG ç³»ç»Ÿ...")
        await self._call_rag_system(dataset)
        self.console.print(f"  [green]âœ“[/green] RAG è°ƒç”¨å®Œæˆ\n")
        
        # 6. æ‰§è¡Œè¯„ä¼°
        self.console.print("[cyan]â–¶[/cyan] [bold]Step 6/6:[/bold] æ‰§è¡Œè¯„ä¼°...")
        await self.runner.run(dataset)
        self.console.print(f"  [green]âœ“[/green] è¯„ä¼°å®Œæˆ\n")
        
        # 7. ç”ŸæˆæŠ¥å‘Š
        self.console.print("[cyan]â–¶[/cyan] [bold]ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...[/bold]")
        await self.reporter.generate_report(
            dataset=dataset,
            output_path=str(work_dir)
        )
        self.console.print(f"  [green]âœ“[/green] æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        execution_time = time.time() - start_time
        avg_score = self._compute_avg_score(dataset)
        metrics_summary = self._compute_metrics_summary(dataset)
        
        result = EvalResult(
            dataset_path=dataset_path,
            report_markdown_path=work_dir / "evaluation_report.md",
            report_excel_path=work_dir / "evaluation_report.xlsx",
            total_cases=len(dataset.cases),
            avg_score=avg_score,
            metrics_summary=metrics_summary,
            execution_time=execution_time,
            timestamp=timestamp
        )
        
        # æ˜¾ç¤ºç»“æœ
        self.console.print(Panel.fit(
            f"[bold green]âœ¨ è¯„ä¼°å®Œæˆï¼[/bold green]\n\n"
            f"[bold]æ€»æµ‹è¯•ç”¨ä¾‹[/bold]: {result.total_cases}\n"
            f"[bold]å¹³å‡åˆ†æ•°[/bold]: {result.avg_score:.2f}\n"
            f"[bold]æ‰§è¡Œè€—æ—¶[/bold]: {result.execution_time:.1f}s\n\n"
            f"[bold cyan]æ‰€æœ‰ç»“æœæ–‡ä»¶å‡ä¿å­˜åœ¨[/bold cyan]:\n"
            f"  {work_dir}",
            title="ğŸ‰ è¯„ä¼°ç»“æœ",
            border_style="green"
        ))
        self.console.print()
        
        return result
    
    async def _generate_dataset(self, units) -> EvalDataset:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®é›†"""
        # ç”Ÿæˆ Personas
        personas = await generate_personas(
            llm_uri=self.config.llm_uri,
            api_key=self.config.api_key,
            domain=self.config.domain,
            num_personas=self.config.num_personas,
            persona_model=HomeBuyerPersona
        )
        
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        dataset = await generate_single_hop(
            llm_uri=self.config.llm_uri,
            api_key=self.config.api_key,
            units=units,
            personas=personas,
            num_cases=self.config.num_test_cases,
            domain=self.config.domain
        )
        
        return dataset
    
    async def _call_rag_system(self, dataset: EvalDataset):
        """è°ƒç”¨ RAG ç³»ç»Ÿ
        
        å°†æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹çš„ question å‘é€åˆ° RAG ç³»ç»Ÿï¼Œè·å–æ£€ç´¢ç»“æœ
        æ³¨æ„ï¼šRAG åªè´Ÿè´£æ£€ç´¢ï¼Œä¸ç”Ÿæˆç­”æ¡ˆï¼Œæ‰€ä»¥ answer è®¾ä¸ºç©ºå­—ç¬¦ä¸²
        """
        import httpx
        from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
        
        total_cases = len(dataset.cases)
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TextColumn("â€¢"),
            TextColumn("{task.completed}/{task.total}"),
            TimeElapsedColumn(),
            console=self.console
        ) as progress:
            task = progress.add_task("[cyan]è°ƒç”¨ RAG...", total=total_cases)
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                for idx, case in enumerate(dataset.cases, 1):
                    try:
                        response = await client.post(
                            f"{self.config.rag_base_url}/datasets/{self.config.rag_dataset_id}/query",
                            json={
                                "query": case.question,
                                "top_k": self.config.rag_top_k,
                                "filters": {}
                            }
                        )
                        
                        if response.status_code == 200:
                            results = response.json().get("data", [])
                            # RAG åªè´Ÿè´£æ£€ç´¢ï¼Œä¸ç”Ÿæˆç­”æ¡ˆ
                            case.answer = ""
                            # ä½¿ç”¨æ£€ç´¢åˆ°çš„ contexts
                            case.retrieved_contexts = [r["content"] for r in results]
                            progress.update(task, advance=1, description=f"[cyan]è°ƒç”¨ RAG... [green]âœ“[/green] Case {idx}")
                        else:
                            self.console.print(
                                f"  [yellow]![/yellow] Case {idx} RAG è°ƒç”¨å¤±è´¥ (HTTP {response.status_code})"
                            )
                            case.answer = ""
                            case.retrieved_contexts = []
                            progress.update(task, advance=1, description=f"[cyan]è°ƒç”¨ RAG... [yellow]![/yellow] Case {idx}")
                            
                    except Exception as e:
                        self.console.print(
                            f"  [yellow]![/yellow] Case {idx} RAG è°ƒç”¨å¼‚å¸¸: {str(e)[:50]}..."
                        )
                        case.answer = ""
                        case.retrieved_contexts = []
                        progress.update(task, advance=1, description=f"[cyan]è°ƒç”¨ RAG... [red]âœ—[/red] Case {idx}")
    
    def _compute_avg_score(self, dataset: EvalDataset) -> float:
        """è®¡ç®—å¹³å‡åˆ†"""
        if not dataset.cases:
            return 0.0
        
        total_score = sum(
            case.overall_score for case in dataset.cases 
            if case.overall_score is not None
        )
        return total_score / len(dataset.cases)
    
    def _compute_metrics_summary(self, dataset: EvalDataset) -> dict[str, float]:
        """è®¡ç®—å„æŒ‡æ ‡å¹³å‡åˆ†"""
        metrics_summary = {}
        
        if not dataset.cases:
            return metrics_summary
        
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡åç§°
        all_metric_names = set()
        for case in dataset.cases:
            if case.results:
                all_metric_names.update(case.results.keys())
        
        # è®¡ç®—æ¯ä¸ªæŒ‡æ ‡çš„å¹³å‡åˆ†
        for metric_name in all_metric_names:
            scores = [
                case.results[metric_name].score
                for case in dataset.cases
                if metric_name in case.results and case.results[metric_name].score is not None
            ]
            if scores:
                metrics_summary[metric_name] = sum(scores) / len(scores)
        
        return metrics_summary
    
    def _extract_pages(
        self, 
        pdf_path: str, 
        start_page: int | None = None, 
        end_page: int | None = None,
        work_dir: Path | None = None
    ) -> str:
        """æå–æŒ‡å®šé¡µç èŒƒå›´çš„ PDF
        
        Args:
            pdf_path: åŸå§‹PDFè·¯å¾„
            start_page: èµ·å§‹é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
            end_page: ç»“æŸé¡µç ï¼ˆåŒ…å«ï¼‰
            work_dir: å·¥ä½œç›®å½•
            
        Returns:
            æå–åçš„PDFæ–‡ä»¶è·¯å¾„ï¼ˆä¸´æ—¶æ–‡ä»¶ï¼‰
        """
        from PyPDF2 import PdfReader, PdfWriter
        
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        
        # ç¡®å®šå®é™…çš„èµ·æ­¢é¡µç 
        actual_start = (start_page - 1) if start_page else 0  # è½¬ä¸º0-basedç´¢å¼•
        actual_end = end_page if end_page else total_pages
        
        # æ ¡éªŒé¡µç èŒƒå›´
        if actual_start < 0:
            actual_start = 0
        if actual_end > total_pages:
            actual_end = total_pages
        if actual_start >= actual_end:
            raise ValueError(
                f"æ— æ•ˆçš„é¡µç èŒƒå›´: {start_page}-{end_page}ï¼Œ"
                f"æ–‡æ¡£æ€»é¡µæ•°: {total_pages}"
            )
        
        # åˆ›å»ºè¾“å‡ºPDF
        writer = PdfWriter()
        for i in range(actual_start, actual_end):
            writer.add_page(reader.pages[i])
        
        # ä¿å­˜åˆ°å·¥ä½œç›®å½•
        temp_filename = f"{Path(pdf_path).stem}_p{actual_start+1}-{actual_end}.pdf"
        temp_path = work_dir / temp_filename
        
        with open(temp_path, "wb") as f:
            writer.write(f)
        
        self.console.print(
            f"  [blue]â„¹[/blue] å·²æå–é¡µç  {actual_start+1}-{actual_end} "
            f"(å…± {actual_end - actual_start} é¡µ)\n"
        )
        
        return str(temp_path)
